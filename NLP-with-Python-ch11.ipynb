{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Managing Linguistic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Corpus Structure: a Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h#',\n",
       " 'sh',\n",
       " 'iy',\n",
       " 'hv',\n",
       " 'ae',\n",
       " 'dcl',\n",
       " 'y',\n",
       " 'ix',\n",
       " 'dcl',\n",
       " 'd',\n",
       " 'aa',\n",
       " 'kcl',\n",
       " 's',\n",
       " 'ux',\n",
       " 'tcl',\n",
       " 'en',\n",
       " 'gcl',\n",
       " 'g',\n",
       " 'r',\n",
       " 'iy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetic = nltk.corpus.timit.phones('dr1-fvmh0/sa1')\n",
    "phonetic[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 7812, 10610),\n",
       " ('had', 10610, 14496),\n",
       " ('your', 14496, 15791),\n",
       " ('dark', 15791, 20720),\n",
       " ('suit', 20720, 25647),\n",
       " ('in', 25647, 26906),\n",
       " ('greasy', 26906, 32668),\n",
       " ('wash', 32668, 37890),\n",
       " ('water', 38531, 42417),\n",
       " ('all', 43091, 46052),\n",
       " ('year', 46052, 50522)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.timit.word_times('dr1-fvmh0/sa1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'r', 'iy1', 's', 'iy', 'w', 'ao1', 'sh', 'w', 'ao1', 't', 'axr']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timitdict = nltk.corpus.timit.transcription_dict()\n",
    "timitdict['greasy'] + timitdict['wash'] + timitdict['water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'r', 'iy', 's', 'iy', 'w', 'aa', 'sh', 'epi', 'w', 'aa', 'dx', 'ax']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetic[17:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeakerInfo(id='VMH0', sex='F', dr='1', use='TRN', recdate='03/11/86', birthdate='01/08/60', ht='5\\'05\"', race='WHT', edu='BS', comments='BEST NEW ENGLAND ACCENT SO FAR')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.timit.spkrinfo('dr1-fvmh0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 The Life-Cycle of a Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"00000010000000001000000\"\n",
    "s2 = \"00000001000000010000000\"\n",
    "s3 = \"00010000000000000001000\"\n",
    "nltk.windowdiff(s1, s1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19047619047619047"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.windowdiff(s1, s2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.windowdiff(s2, s3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Acquiring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "legal_pos = set(['n', 'v.t.', 'v.i.', 'adj', 'det'])\n",
    "pattern = re.compile(r\"'font-size:11.0pt'>([a-z.]+)<\")\n",
    "document = open(\"dict.htm\", encoding=\"utf-8\").read()\n",
    "used_pos = set(re.findall(pattern, document))\n",
    "illegal_pos = used_pos.difference(legal_pos)\n",
    "print(list(illegal_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p class=MsoNormal>sleep\\n  <span style='mso-spacerun:yes'> </span>\\n  [<span class=SpellE>sli:p</span>]\\n  <span style='mso-spacerun:yes'> </span>\\n  <b><span style='font-size:11.0pt'>v.i.</span></b>\\n  <span style='mso-spacerun:yes'> </span>\\n  <i>a condition of body and mind ...<o:p></o:p></i>\\n</p>\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v.i.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def lexical_data(html_file, encoding=\"utf-8\"):\n",
    "    SEP = '_ENTRY'\n",
    "    html = open(html_file, encoding=encoding).read()\n",
    "    html = re.sub(r'<p', SEP + '<p', html)\n",
    "    text = BeautifulSoup(html).get_text()\n",
    "    text = ' '.join(text.split())\n",
    "    for entry in text.split(SEP):\n",
    "        if entry.count(' ') > 2:\n",
    "            yield entry.split(' ', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['...',\n",
       " 'a',\n",
       " 'and',\n",
       " 'body',\n",
       " 'by',\n",
       " 'cease',\n",
       " 'condition',\n",
       " 'down',\n",
       " 'each',\n",
       " 'foot',\n",
       " 'lifting',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'progress',\n",
       " 'setting',\n",
       " 'to']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "lexicon = csv.reader(open('dict.csv'))\n",
    "pairs = [(lexeme, defn) for (lexeme, _, _, defn) in lexicon]\n",
    "lexemes, defns = zip(*pairs)\n",
    "defn_words = set(w for defn in defns for w in defn.split())\n",
    "sorted(defn_words.difference(lexemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = nltk.Index((defn_word, lexeme)\n",
    "                for (lexeme, defn) in pairs\n",
    "                for defn_word in nltk.word_tokenize(defn)\n",
    "                if len(defn_word) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"dict.idx\", \"w\") as idx_file:\n",
    "    for word in sorted(idx):\n",
    "        idx_words = ', '.join(idx[word])\n",
    "        idx_line = \"{}: {}\".format(word, idx_words)\n",
    "        print(idx_line, file=idx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mappings = [('ph', 'f'), ('ght', 't'), ('^kn', 'n'), ('qu', 'kw'),\n",
    "            ('[aeiou]+', 'a'), (r'(.)\\1', r'\\1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def signature(word):\n",
    "    for patt, repl in mappings:\n",
    "        word = re.sub(patt, repl, word)\n",
    "    pieces = re.findall('[^aeiou]+', word)\n",
    "    return ''.join(char for piece in pieces for char in sorted(piece))[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lfnt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature('illefent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bskws'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature('ebsekwieous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nclr'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature('nuculerr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anicular',\n",
       " 'inocular',\n",
       " 'nucellar',\n",
       " 'nuclear',\n",
       " 'unicolor',\n",
       " 'uniocular',\n",
       " 'unocular']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures = nltk.Index((signature(w), w) for w in nltk.corpus.words.words())\n",
    "signatures[signature('nuculerr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(word, wordlist):\n",
    "    ranked = sorted((nltk.edit_distance(word, w), w) for w in wordlist)\n",
    "    return [word for (_, word) in ranked]\n",
    "\n",
    "def fuzzy_spell(word):\n",
    "    sig = signature(word)\n",
    "    if sig in signatures:\n",
    "        return rank(word, signatures[sig])\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olefiant', 'elephant', 'oliphant', 'elephanta']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_spell('illefent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obsequious']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_spell('ebsekwieous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anicular',\n",
       " 'inocular',\n",
       " 'nucellar',\n",
       " 'nuclear',\n",
       " 'unocular',\n",
       " 'uniocular',\n",
       " 'unicolor']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_spell('nucular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.4 Working with XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<?xml-stylesheet type=\"text/css\" href=\"shakes.css\"?>\n",
      "<!-- <!DOCTYPE PLAY SYSTEM \"play.dtd\"> -->\n",
      "\n",
      "<PLAY>\n",
      "<TITLE>The Merchant of Venice</TITLE>\n"
     ]
    }
   ],
   "source": [
    "merchant_file = nltk.data.find('corpora/shakespeare/merchant.xml')\n",
    "raw = open(merchant_file).read()\n",
    "print(raw[:163])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TITLE>ACT I</TITLE>\n",
      "\n",
      "<SCENE><TITLE>SCENE I.  Venice. A street.</TITLE>\n",
      "<STAGEDIR>Enter ANTONIO, SALARINO, and SALANIO</STAGEDIR>\n",
      "\n",
      "<SPEECH>\n",
      "<SPEAKER>ANTONIO</SPEAKER>\n",
      "<LINE>In sooth, I know not why I am so sad:</LINE>\n"
     ]
    }
   ],
   "source": [
    "print(raw[1789:2006])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'PLAY' at 0x7f1f3ec7b908>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import ElementTree\n",
    "merchant = ElementTree().parse(merchant_file) \n",
    "merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'TITLE' at 0x7f1f3ec7b9f8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Merchant of Venice'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'TITLE' at 0x7f1f3ec7b9f8>,\n",
       " <Element 'PERSONAE' at 0x7f1f3ec7bc28>,\n",
       " <Element 'SCNDESCR' at 0x7f1f3ec81728>,\n",
       " <Element 'PLAYSUBT' at 0x7f1f3ec81778>,\n",
       " <Element 'ACT' at 0x7f1f3ec817c8>,\n",
       " <Element 'ACT' at 0x7f1f3ec1e408>,\n",
       " <Element 'ACT' at 0x7f1f3ec4ec28>,\n",
       " <Element 'ACT' at 0x7f1f3ebfc228>,\n",
       " <Element 'ACT' at 0x7f1f3eb9fc28>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACT IV'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'SCENE' at 0x7f1f3ebfc2c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SCENE I.  Venice. A court of justice.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'SPEECH' at 0x7f1f3ec0a3b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'SPEAKER' at 0x7f1f3ec0a408>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][54][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PORTIA'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][54][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'LINE' at 0x7f1f3ec0a458>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][54][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The quality of mercy is not strain'd,\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant[-2][1][54][1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act 3 Scene 2 Speech 9: Let music sound while he doth make his choice;\n",
      "Act 3 Scene 2 Speech 9: Fading in music: that the comparison\n",
      "Act 3 Scene 2 Speech 9: And what is music then? Then music is\n",
      "Act 5 Scene 1 Speech 23: And bring your music forth into the air.\n",
      "Act 5 Scene 1 Speech 23: Here will we sit and let the sounds of music\n",
      "Act 5 Scene 1 Speech 23: And draw her home with music.\n",
      "Act 5 Scene 1 Speech 24: I am never merry when I hear sweet music.\n",
      "Act 5 Scene 1 Speech 25: Or any air of music touch their ears,\n",
      "Act 5 Scene 1 Speech 25: By the sweet power of music: therefore the poet\n",
      "Act 5 Scene 1 Speech 25: But music for the time doth change his nature.\n",
      "Act 5 Scene 1 Speech 25: The man that hath no music in himself,\n",
      "Act 5 Scene 1 Speech 25: Let no such man be trusted. Mark the music.\n",
      "Act 5 Scene 1 Speech 29: It is your music, madam, of the house.\n",
      "Act 5 Scene 1 Speech 32: No better a musician than the wren.\n"
     ]
    }
   ],
   "source": [
    "for i, act in enumerate(merchant.findall('ACT')):\n",
    "    for j, scene in enumerate(act.findall('SCENE')):\n",
    "        for k, speech in enumerate(scene.findall('SPEECH')):\n",
    "            for line in speech.findall('LINE'):\n",
    "                if 'music' in str(line.text):\n",
    "                    print(\"Act %d Scene %d Speech %d: %s\" % (i+1, j+1, k+1, line.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PORTIA', 117),\n",
       " ('SHYLOCK', 79),\n",
       " ('BASSANIO', 73),\n",
       " ('GRATIANO', 48),\n",
       " ('ANTONIO', 47)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "speaker_seq = [s.text for s in merchant.findall('ACT/SCENE/SPEECH/SPEAKER')]\n",
    "speaker_freq = Counter(speaker_seq)\n",
    "top5 = speaker_freq.most_common(5)\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "abbreviate = defaultdict(lambda: 'OTH')\n",
    "for speaker, _ in top5:\n",
    "    abbreviate[speaker] = speaker[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ANTO BASS GRAT  OTH PORT SHYL \n",
      "ANTO    0   11    4   11    9   12 \n",
      "BASS   10    0   11   10   26   16 \n",
      "GRAT    6    8    0   19    9    5 \n",
      " OTH    8   16   18  153   52   25 \n",
      "PORT    7   23   13   53    0   21 \n",
      "SHYL   15   15    2   26   21    0 \n"
     ]
    }
   ],
   "source": [
    "speaker_seq2 = [abbreviate[speaker] for speaker in speaker_seq]\n",
    "cfd = nltk.ConditionalFreqDist(nltk.bigrams(speaker_seq2))\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import toolbox\n",
    "lexicon = toolbox.xml('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'lx' at 0x7f1f3ebb9e08>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lx'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon[3][0].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaa'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon[3][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaa',\n",
       " 'kaa',\n",
       " 'kaa',\n",
       " 'kaakaaro',\n",
       " 'kaakaaviko',\n",
       " 'kaakaavo',\n",
       " 'kaakaoko',\n",
       " 'kaakasi',\n",
       " 'kaakau',\n",
       " 'kaakauko',\n",
       " 'kaakito',\n",
       " 'kaakuupato',\n",
       " 'kaaova',\n",
       " 'kaapa',\n",
       " 'kaapea',\n",
       " 'kaapie',\n",
       " 'kaapie',\n",
       " 'kaapiepato',\n",
       " 'kaapisi',\n",
       " 'kaapisivira']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lexeme.text.lower() for lexeme in lexicon.findall('record/lx')][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<record>\n",
      "    <lx>kaa</lx>\n",
      "    <ps>N</ps>\n",
      "    <pt>MASC</pt>\n",
      "    <cl>isi</cl>\n",
      "    <ge>cooking banana</ge>\n",
      "    <tkp>banana bilong kukim</tkp>\n",
      "    <pt>itoo</pt>\n",
      "    <sf>FLORA</sf>\n",
      "    <dt>12/Aug/2005</dt>\n",
      "    <ex>Taeavi iria kaa isi kovopaueva kaparapasia.</ex>\n",
      "    <xp>Taeavi i bin planim gaden banana bilong kukim tasol long paia.</xp>\n",
      "    <xe>Taeavi planted banana in order to cook it.</xe>\n",
      "  </record>"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nltk.util import elementtree_indent\n",
    "from xml.etree.ElementTree import ElementTree\n",
    "elementtree_indent(lexicon)\n",
    "tree = ElementTree(lexicon[3])\n",
    "tree.write(sys.stdout, encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <tr><td>kakae</td><td>???</td><td>small</td></tr>\n",
      "  <tr><td>kakae</td><td>CLASS</td><td>child</td></tr>\n",
      "  <tr><td>kakaevira</td><td>ADV</td><td>small-like</td></tr>\n",
      "  <tr><td>kakapikoa</td><td>???</td><td>small</td></tr>\n",
      "  <tr><td>kakapikoto</td><td>N</td><td>newborn baby</td></tr>\n",
      "  <tr><td>kakapu</td><td>V</td><td>place in sling for purpose of carrying</td></tr>\n",
      "  <tr><td>kakapua</td><td>N</td><td>sling for lifting</td></tr>\n",
      "  <tr><td>kakara</td><td>N</td><td>arm band</td></tr>\n",
      "  <tr><td>Kakarapaia</td><td>N</td><td>village name</td></tr>\n",
      "  <tr><td>kakarau</td><td>N</td><td>frog</td></tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "html = \"<table>\\n\"\n",
    "for entry in lexicon[70:80]:\n",
    "    lx = entry.findtext('lx')\n",
    "    ps = entry.findtext('ps')\n",
    "    ge = entry.findtext('ge')\n",
    "    html += \"  <tr><td>%s</td><td>%s</td><td>%s</td></tr>\\n\" % (lx, ps, ge)\n",
    "html += \"</table>\"\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Working with Toolbox Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.635955056179775"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import toolbox\n",
    "lexicon = toolbox.xml('rotokas.dic')\n",
    "sum(len(entry) for entry in lexicon) / len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import SubElement\n",
    "\n",
    "def cv(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z]',     r'_', s)\n",
    "    s = re.sub(r'[aeiou]',    r'V', s)\n",
    "    s = re.sub(r'[^V_]',      r'C', s)\n",
    "    return (s)\n",
    "\n",
    "def add_cv_field(entry):\n",
    "    for field in entry:\n",
    "        if field.tag == 'lx':\n",
    "            cv_field = SubElement(entry, 'cv')\n",
    "            cv_field.text = cv(field.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\lx kaeviro\n",
      "\\ps V\n",
      "\\pt A\n",
      "\\ge lift off\n",
      "\\ge take off\n",
      "\\tkp go antap\n",
      "\\sc MOTION\n",
      "\\vx 1\n",
      "\\nt used to describe action of plane\n",
      "\\dt 03/Jun/2005\n",
      "\\ex Pita kaeviroroe kepa kekesia oa vuripierevo kiuvu.\n",
      "\\xp Pita i go antap na lukim haus win i bagarapim.\n",
      "\\xe Peter went to look at the house that the wind destroyed.\n",
      "\\cv CVVCVCV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lexicon = toolbox.xml('rotokas.dic')\n",
    "add_cv_field(lexicon[53])\n",
    "print(nltk.toolbox.to_sfm_string(lexicon[53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lx:ps:pt:ge:tkp:dt:ex:xp:xe', 41),\n",
       " ('lx:rt:ps:pt:ge:tkp:dt:ex:xp:xe', 37),\n",
       " ('lx:rt:ps:pt:ge:tkp:dt:ex:xp:xe:ex:xp:xe', 27),\n",
       " ('lx:ps:pt:ge:tkp:nt:dt:ex:xp:xe', 20),\n",
       " ('lx:ps:pt:ge:tkp:nt:dt:ex:xp:xe:ex:xp:xe', 17),\n",
       " ('lx:ps:pt:ge:tkp:dt:ex:xp:xe:ex:xp:xe', 16),\n",
       " ('lx:rt:ps:pt:ge:ge:tkp:dt:ex:xp:xe:ex:xp:xe', 12),\n",
       " ('lx:ps:pt:ge:ge:tkp:dt:ex:xp:xe', 9),\n",
       " ('lx:rt:ps:pt:ge:tkp:dt:ex:xp:xe:ex:xp:xe:ex:xp:xe', 9),\n",
       " ('lx:ps:pt:ge:tkp:nt:sf:dt:ex:xp:xe', 9)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "field_sequences = Counter(':'.join(field.tag for field in entry) for entry in lexicon)\n",
    "field_sequences.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring('''\n",
    "  S -> Head PS Glosses Comment Date Sem_Field Examples\n",
    "  Head -> Lexeme Root\n",
    "  Lexeme -> \"lx\"\n",
    "  Root -> \"rt\" |\n",
    "  PS -> \"ps\"\n",
    "  Glosses -> Gloss Glosses |\n",
    "  Gloss -> \"ge\" | \"tkp\" | \"eng\"\n",
    "  Date -> \"dt\"\n",
    "  Sem_Field -> \"sf\"\n",
    "  Examples -> Example Ex_Pidgin Ex_English Examples |\n",
    "  Example -> \"ex\"\n",
    "  Ex_Pidgin -> \"xp\"\n",
    "  Ex_English -> \"xe\"\n",
    "  Comment -> \"cmt\" | \"nt\" |\n",
    "  ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_lexicon(grammar, lexicon, ignored_tags):\n",
    "    rd_parser = nltk.RecursiveDescentParser(grammar)\n",
    "    for entry in lexicon:\n",
    "        marker_list = [field.tag for field in entry if field.tag not in ignored_tags]\n",
    "        if list(rd_parser.parse(marker_list)):\n",
    "            print(\"+\", ':'.join(marker_list))\n",
    "        else:\n",
    "            print(\"-\", ':'.join(marker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- lx:ps:ge:tkp:sf:nt:dt:ex:xp:xe:ex:xp:xe:ex:xp:xe\n",
      "- lx:rt:ps:ge:tkp:nt:dt:ex:xp:xe:ex:xp:xe\n",
      "- lx:ps:ge:tkp:nt:dt:ex:xp:xe:ex:xp:xe\n",
      "- lx:ps:ge:tkp:nt:sf:dt\n",
      "- lx:ps:ge:tkp:dt:cmt:ex:xp:xe:ex:xp:xe\n",
      "- lx:ps:ge:ge:ge:tkp:cmt:dt:ex:xp:xe\n",
      "- lx:rt:ps:ge:ge:tkp:dt\n",
      "- lx:rt:ps:ge:eng:eng:eng:ge:tkp:tkp:dt:cmt:ex:xp:xe:ex:xp:xe:ex:xp:xe:ex:xp:xe:ex:xp:xe\n",
      "- lx:rt:ps:ge:tkp:dt:ex:xp:xe\n",
      "- lx:ps:ge:ge:tkp:dt:ex:xp:xe:ex:xp:xe\n"
     ]
    }
   ],
   "source": [
    "lexicon = toolbox.xml('rotokas.dic')[10:20]\n",
    "ignored_tags = ['arg', 'dcsv', 'pt', 'vx'] \n",
    "validate_lexicon(grammar, lexicon, ignored_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "      lexfunc: {<lf>(<lv><ln|le>*)*}\n",
    "      example: {<rf|xv><xn|xe>*}\n",
    "      sense:   {<sn><ps><pn|gv|dv|gn|gp|dn|rn|ge|de|re>*<example>*<lexfunc>*}\n",
    "      record:   {<lx><hm><sense>+<dt>}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-fb0244a14eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolboxData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/toolbox/iu_mien_samp.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iu_mien_samp.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, grammar, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36m_chunk_parse\u001b[0;34m(self, grammar, root_label, trace, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegexpParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mtb_etree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'toolbox_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, grammar, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_record_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36m_record_parse\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0min_records\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmkr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_records\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmkr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmkr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36mfields\u001b[0;34m(self, strip, unwrap, encoding, errors, unicode_fields)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode_fields is set but not encoding.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0munwrap_pat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\n+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmkr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# kludge - already decoded in PY3?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0municode_fields\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmkr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0municode_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/site-packages/nltk/toolbox.py\u001b[0m in \u001b[0;36mraw_fields\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mfile_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mmobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line_pat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mmkr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mvalue_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pub/anaconda3/lib/python3.5/re.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[1;32m    162\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import ElementTree\n",
    "from nltk.toolbox import ToolboxData\n",
    "db = ToolboxData()\n",
    "db.open(nltk.data.find('corpora/toolbox/iu_mien_samp.db'))\n",
    "lexicon = db.parse(grammar, encoding='utf-8')\n",
    "tree = ElementTree(lexicon)\n",
    "with open(\"iu_mien_samp.xml\", \"wb\") as output:\n",
    "    tree.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n      lexfunc: {<lf>(<lv><ln|le>*)*}\\n      example: {<rf|xv><xn|xe>*}\\n      sense:   {<sn><ps><pn|gv|dv|gn|gp|dn|rn|ge|de|re>*<example>*<lexfunc>*}\\n      record:   {<lx><hm><sense>+<dt>}\\n    '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 11.6 Describing Language Resources using OLAC Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
